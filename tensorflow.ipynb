{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET #tree import \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_IMAGES = 200\n",
    "TRAIN_IMAGES = 2000\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "GRID_SIZE = 5\n",
    "BOX_SIZE = 1 #originally 2 boxes -> choose the one with the highest iou => we will not do in here\n",
    "NUM_CLASS = 2\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotations = 'C:\\\\Users\\\\INFOSTAT-19\\\\Desktop\\\\annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesNum = {'dog': 0, 'cat': 1}\n",
    "def convertFunction(folder, name, file):\n",
    "    path = folder + '/' + name\n",
    "    path = os.path.normpath(path)\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    file.write(path.replace('xml', 'png'))\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        className = obj.find('name').text\n",
    "        if className not in classesNum.keys() or int(difficult) == 1:\n",
    "            continue\n",
    "\n",
    "        #get bounding box\n",
    "        box = ( int(obj.find('bndbox').find('xmin').text),\n",
    "                int(obj.find('bndbox').find('ymin').text),\n",
    "                int(obj.find('bndbox').find('xmax').text),\n",
    "                int(obj.find('bndbox').find('ymax').text))\n",
    "\n",
    "        id = list(classesNum.keys()).index(className)\n",
    "\n",
    "        #write to file\n",
    "        file.write(' ' + ','.join([str(a) for a in box]) + ',' + str(id))\n",
    "    file.write('\\n')\n",
    "\n",
    "with open(os.path.join('%s.txt' % ('annotations')) , 'w') as f:\n",
    "    for file in os.listdir('annotations'):\n",
    "        if file.endswith('.xml'):\n",
    "            convertFunction(folder = 'annotations', name=str(file), file=f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = []\n",
    "with open(os.path.normpath('annotations.txt'), 'r') as f:\n",
    "    train_datasets = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datasets = train_datasets[:VALIDATION_IMAGES]\n",
    "train_datasets = train_datasets[VALIDATION_IMAGES : VALIDATION_IMAGES + TRAIN_IMAGES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images:  2000 Val images:  200\n"
     ]
    }
   ],
   "source": [
    "print('Train images: ', len(train_datasets), 'Val images: ', len(val_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classArray  = list(classesNum.keys())\n",
    "\n",
    "def annotationConverting(dataset):\n",
    "    X, Y = [], []\n",
    "    for item in dataset:\n",
    "        item = item.replace(\"\\n\", \"\").split(\" \")\n",
    "        X.append(item[0])\n",
    "        arr = []\n",
    "        for i in range(1, len(item)):\n",
    "            arr.append(item[i])\n",
    "        Y.append(arr)\n",
    "    return X,Y\n",
    "#def testPrintItem(Image,target):\n",
    "   #pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = annotationConverting(train_datasets)\n",
    "X_val, Y_val = annotationConverting(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['69,42,239,224,0']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images, labels, shuffle=False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.images) / int(BATCH_SIZE))).astype(int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.images[idx * BATCH_SIZE : (idx + 1) * BATCH_SIZE] # images path\n",
    "        batch_y = self.labels[idx * BATCH_SIZE : (idx + 1) * BATCH_SIZE] # raw label\n",
    "\n",
    "        train_image, train_label = [], []\n",
    "        for i in range(0, len(batch_x)):\n",
    "            img_path, label = batch_x[i], batch_y[i]\n",
    "            image, label_matrix = self.read(img_path, label) #actual image array (IMAGE_SIZE, IMAGE_SIZE, 3) (GRID_SIZE, GRID_SIZE, 5 * BOX_SIZE + CLASS) \n",
    "            train_image.append(image)\n",
    "            train_label.append(label_matrix)\n",
    "        \n",
    "        if self.shuffle:\n",
    "            indices = tf.range(start=0, limit=tf.shape(train_image)[0], dtype=tf.int32)\n",
    "            idx = tf.random.shuffle(indices)\n",
    "            train_image = tf.gather(train_image, idx)\n",
    "            train_label = tf.gather(train_label, idx)\n",
    "\n",
    "        return np.array(train_image, dtype=np.float32), np.array(train_label, dtype=np.float32)\n",
    "    \n",
    "    def read(self, img_path, label):\n",
    "        image = cv.imread(img_path)\n",
    "        h, w = image.shape[0:2]\n",
    "        #h, w = image.shape[0]\n",
    "        image = cv.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        image = image / 255.\n",
    "\n",
    "        label_matrix = np.zeros([GRID_SIZE, GRID_SIZE, 5 * BOX_SIZE + NUM_CLASS])\n",
    "        for l in label:\n",
    "            l = l.split(',')\n",
    "            l = np.array(l, dtype=int)\n",
    "\n",
    "            xmin, ymin, xmax, ymax = l[0] / w, l[1] / h, l[2] / w, l[3] / h # [0, 1]\n",
    "            \n",
    "            x, y = (xmin + xmax) / 2, (ymin + ymax) / 2\n",
    "            w, h = xmax - xmin, ymax - ymin\n",
    "\n",
    "            #convert x, y relative to the cell\n",
    "            i, j = int(GRID_SIZE * y), int(GRID_SIZE * x)\n",
    "            x = GRID_SIZE * x - j # 7 * [0,1] = [0, 7] e.g: 6.43 - int(6.43) = 0.43 => relative to the cell\n",
    "            y = GRID_SIZE * y - i\n",
    "\n",
    "            if l[4] == 0:\n",
    "                label_matrix[i, j] = [x, y, w, h, 1, 1, 0]\n",
    "            if l[4] == 1:\n",
    "                label_matrix[i, j] = [x, y, w, h, 1, 0, 1]\n",
    "        return image, label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size 128 -> 1300 load all of them to our ram before they can go to the gpu for training -> memory expensive\n",
    "#data generator gonna generator 128 images every step in the fit function -> not expensive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['83,29,197,142,1'], ['128,22,240,222,0'], ['157,56,264,116,0'], ['142,145,206,209,1'], ['36,14,289,312,1'], ['140,80,229,152,0'], ['178,107,294,223,1'], ['148,39,355,244,0'], ['53,27,239,121,0'], ['65,16,294,221,1'], ['95,20,299,290,0'], ['225,52,381,195,1'], ['108,149,199,229,1'], ['70,48,168,120,0'], ['134,79,297,234,1'], ['36,65,137,172,1'], ['112,64,217,164,1'], ['94,36,378,263,0'], ['130,38,237,132,0'], ['195,61,374,177,1'], ['94,35,235,136,0'], ['120,1,331,222,0'], ['336,15,486,158,1'], ['102,42,208,146,0'], ['160,6,416,265,1'], ['165,30,327,187,1'], ['194,121,295,228,0'], ['86,28,306,258,1'], ['85,43,210,164,0'], ['158,3,384,183,1'], ['65,36,199,166,0'], ['274,84,402,207,0'], ['1,42,328,308,1'], ['224,41,394,216,1'], ['83,1,217,147,0'], ['1,100,375,453,1'], ['95,17,258,167,0'], ['255,30,354,111,0'], ['100,15,241,135,0'], ['203,7,343,159,1'], ['87,26,288,249,0'], ['131,80,432,366,1'], ['118,10,292,217,1'], ['84,17,223,138,0'], ['88,85,266,231,0'], ['102,15,272,204,1'], ['126,104,248,197,0'], ['198,108,275,190,1'], ['339,90,422,166,1'], ['68,96,199,248,0'], ['165,31,356,235,1'], ['38,92,136,192,1'], ['222,188,406,348,0'], ['98,105,246,255,1'], ['23,135,293,422,0'], ['103,47,330,268,0'], ['220,38,347,235,0'], ['139,136,368,297,0'], ['205,46,277,115,1'], ['151,166,249,263,0'], ['125,50,257,173,0'], ['170,87,222,159,0'], ['111,47,240,154,1'], ['86,1,187,107,0'], ['17,25,206,180,1'], ['224,36,437,219,0'], ['215,23,393,176,1'], ['127,26,333,305,0'], ['138,107,259,227,1'], ['110,53,330,247,0'], ['79,1,268,267,0'], ['177,75,262,206,0'], ['115,106,341,255,0'], ['68,6,153,67,0'], ['39,51,156,179,1'], ['212,86,289,176,1'], ['39,21,263,320,0'], ['195,49,248,107,1'], ['140,132,230,208,0'], ['208,21,381,155,0'], ['79,14,228,203,1'], ['277,64,404,191,1'], ['221,21,454,277,1'], ['225,80,315,170,0'], ['71,1,182,109,1'], ['20,10,176,169,1'], ['80,64,233,174,0'], ['191,54,390,257,0'], ['132,52,277,165,0'], ['293,49,443,193,1'], ['130,85,330,260,0'], ['144,53,275,197,1'], ['107,56,455,308,0'], ['84,17,225,160,1'], ['68,24,388,303,0'], ['134,96,369,330,0'], ['98,1,299,201,0'], ['36,40,192,216,0'], ['140,100,295,247,0'], ['256,110,340,193,0'], ['100,92,255,236,0'], ['307,80,409,157,0'], ['124,176,336,418,0'], ['315,60,446,219,1'], ['141,13,313,202,0'], ['143,94,302,214,0'], ['129,86,235,194,0'], ['43,57,422,322,0'], ['93,44,215,126,0'], ['211,131,276,195,0'], ['95,54,193,155,0'], ['96,35,234,185,1'], ['120,1,441,280,1'], ['160,21,340,230,1'], ['232,105,333,190,0'], ['68,58,468,364,0'], ['81,28,222,188,1'], ['187,24,469,317,0'], ['68,73,242,251,1'], ['170,15,402,269,1'], ['101,65,215,156,0'], ['145,1,426,287,0'], ['129,27,359,248,1'], ['107,34,343,270,0'], ['170,141,243,252,0'], ['124,4,375,242,0'], ['388,163,486,287,0'], ['269,168,334,233,0'], ['270,76,329,140,1'], ['177,1,336,160,1'], ['191,48,427,236,0'], ['94,47,296,321,0'], ['222,41,346,171,1'], ['89,110,231,263,0'], ['112,111,280,280,0'], ['175,113,255,188,0'], ['256,88,478,278,0'], ['103,1,442,322,0'], ['117,54,268,184,1'], ['149,103,321,252,0'], ['269,68,396,177,0'], ['164,116,226,162,0'], ['135,62,409,277,0'], ['84,1,242,182,1'], ['171,19,341,296,0'], ['42,31,262,268,1'], ['47,62,108,140,0'], ['76,10,257,148,1'], ['227,62,451,292,0'], ['158,113,267,231,0'], ['1,20,386,321,0'], ['106,91,248,182,0'], ['28,125,216,262,0'], ['117,114,199,206,0'], ['255,81,358,218,0'], ['158,9,410,260,0'], ['25,29,162,190,0'], ['157,46,263,181,0'], ['206,35,406,187,1'], ['29,12,238,243,0'], ['162,45,291,145,0'], ['152,55,257,143,0'], ['219,19,438,329,0'], ['51,1,389,358,0'], ['189,40,302,204,0'], ['61,81,217,197,0'], ['137,25,285,158,0'], ['47,85,101,155,0'], ['143,18,309,169,0'], ['29,25,164,159,1'], ['56,12,176,164,0'], ['323,83,492,217,1'], ['183,76,265,201,0'], ['234,79,454,281,0'], ['192,9,419,248,0'], ['287,157,364,250,0'], ['182,54,285,156,0'], ['169,52,364,221,0'], ['164,76,362,232,0'], ['170,1,382,262,0'], ['47,19,370,294,0'], ['288,76,498,299,0'], ['43,25,273,216,0'], ['253,24,316,104,1'], ['71,28,333,189,0'], ['167,38,342,253,0'], ['115,95,414,292,0'], ['108,41,289,194,1'], ['40,96,305,374,0'], ['118,111,288,295,0'], ['145,35,376,252,1'], ['119,26,353,217,1'], ['198,55,302,187,0'], ['48,76,184,235,0'], ['133,1,228,91,1'], ['80,1,330,225,1'], ['60,38,200,194,1'], ['92,26,224,159,0'], ['30,24,239,177,0'], ['103,110,254,284,0']]\n"
     ]
    }
   ],
   "source": [
    "print(Y_val)\n",
    "#리스트로 나옴 -> 이걸 dataframe으로 만들어야 한다면..? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataGenerator = DataGenerator(X_train, Y_train)\n",
    "validationDataGenerator = DataGenerator(X_val, Y_val)\n",
    "\n",
    "#datagenerator -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DataGenerator object at 0x000001C06AA12DF0>\n"
     ]
    }
   ],
   "source": [
    "print(trainingDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train, y_train \u001b[39m=\u001b[39m trainingDataGenerator\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m \u001b[39m#AttributeError: 'NoneType' object has no attribute 'shape' - \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#이미지가 보일수 없어서 생긴 에러.?\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#The AttributeError: ‘nonetype’ object has no attribute ‘shape’ error occurs when you try to access the shape attribute of an object that is None.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(batch_x)):\n\u001b[0;32m     16\u001b[0m     img_path, label \u001b[39m=\u001b[39m batch_x[i], batch_y[i]\n\u001b[1;32m---> 17\u001b[0m     image, label_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(img_path, label) \u001b[39m#actual image array (IMAGE_SIZE, IMAGE_SIZE, 3) (GRID_SIZE, GRID_SIZE, 5 * BOX_SIZE + CLASS) \u001b[39;00m\n\u001b[0;32m     18\u001b[0m     train_image\u001b[39m.\u001b[39mappend(image)\n\u001b[0;32m     19\u001b[0m     train_label\u001b[39m.\u001b[39mappend(label_matrix)\n",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m, in \u001b[0;36mDataGenerator.read\u001b[1;34m(self, img_path, label)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, img_path, label):\n\u001b[0;32m     30\u001b[0m     image \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(img_path)\n\u001b[1;32m---> 31\u001b[0m     h, w \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n\u001b[0;32m     32\u001b[0m     \u001b[39m#h, w = image.shape[0]\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     image \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mresize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x_train, y_train = trainingDataGenerator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'cat']\n"
     ]
    }
   ],
   "source": [
    "classArray = list(classesNum.keys())\n",
    "print(classArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestPrint(image, label):\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            if label[i][j][4] > 0.5:\n",
    "                print(label[i][j])\n",
    "                x, y, w, h = label[i][j][:4]\n",
    "\n",
    "                xmax = int(((x + j) / GRID_SIZE * IMAGE_SIZE) + (w * IMAGE_SIZE) / 2)\n",
    "                xmin = int(((x + j) / GRID_SIZE * IMAGE_SIZE) - (w * IMAGE_SIZE) / 2)\n",
    "                ymax = int(((y + i) / GRID_SIZE * IMAGE_SIZE) + (h * IMAGE_SIZE) / 2)\n",
    "                ymin = int(((y + i) / GRID_SIZE * IMAGE_SIZE) - (h * IMAGE_SIZE) / 2)\n",
    "\n",
    "                className = classArray[tf.argmax(label[i][j][5:], axis=-1)]\n",
    "                cv.putText(image, className, (xmin, ymax + 10), cv.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 255, 255))\n",
    "                cv.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 255, 255), 1)\n",
    "    #image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    cv.imshow('Visualize', image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyWindow('Visualize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train, y_train \u001b[39m=\u001b[39m trainingDataGenerator\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n\u001b[0;32m      3\u001b[0m TestPrint(x_train[idx], y_train[idx])\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(batch_x)):\n\u001b[0;32m     16\u001b[0m     img_path, label \u001b[39m=\u001b[39m batch_x[i], batch_y[i]\n\u001b[1;32m---> 17\u001b[0m     image, label_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(img_path, label) \u001b[39m#actual image array (IMAGE_SIZE, IMAGE_SIZE, 3) (GRID_SIZE, GRID_SIZE, 5 * BOX_SIZE + CLASS) \u001b[39;00m\n\u001b[0;32m     18\u001b[0m     train_image\u001b[39m.\u001b[39mappend(image)\n\u001b[0;32m     19\u001b[0m     train_label\u001b[39m.\u001b[39mappend(label_matrix)\n",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m, in \u001b[0;36mDataGenerator.read\u001b[1;34m(self, img_path, label)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, img_path, label):\n\u001b[0;32m     30\u001b[0m     image \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(img_path)\n\u001b[1;32m---> 31\u001b[0m     h, w \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n\u001b[0;32m     32\u001b[0m     \u001b[39m#h, w = image.shape[0]\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     image \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mresize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x_train, y_train = trainingDataGenerator.__getitem__(0)\n",
    "idx = 6\n",
    "TestPrint(x_train[idx], y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloActivation(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        classes = tf.nn.softmax(inputs[..., 5:], axis=-1)\n",
    "        coordinates = tf.sigmoid(inputs[..., :5])\n",
    "        return tf.concat([coordinates, classes], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-m_notop.h5\n",
      "214201816/214201816 [==============================] - 7s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 7, 7, 1280)        53150388  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 1280)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3, 3, 1280)       5120      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 11520)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              11797504  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 175)               89775     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 5, 7)           0         \n",
      "                                                                 \n",
      " yolo_activation (YoloActiva  (None, 5, 5, 7)          0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,569,635\n",
      "Trainable params: 12,415,663\n",
      "Non-trainable params: 53,153,972\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, MaxPool2D, BatchNormalization\n",
    "\n",
    "lrelu = tf.keras.layers.LeakyReLU(alpha=0.1)\n",
    "\n",
    "featureExtractor = Sequential()\n",
    "featureExtractor.add(tf.keras.applications.efficientnet_v2.EfficientNetV2M(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "))\n",
    "\n",
    "featureExtractor.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(featureExtractor)\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation=lrelu))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation=lrelu))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(GRID_SIZE * GRID_SIZE * (BOX_SIZE * 5 + NUM_CLASS))) #total nodes we need -> reshape them into the grid (GRID_SIZE, GRID_SIZE, BOX_SIZE * 5 + NUM_CLASS)\n",
    "model.add(Reshape((GRID_SIZE, GRID_SIZE, BOX_SIZE * 5 + NUM_CLASS))) # linear activation function (-inf, inf) -> takes longer to converge and not that good\n",
    "model.add(YoloActivation()) #convert last two class probability into a softmax outputs\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO LOSS !!!\n",
    "def yoloLoss(y_true, y_pred):\n",
    "    coordLoss = CoordLoss(y_true, y_pred)\n",
    "    confidenceLoss = ConfidenceLoss(y_true, y_pred)\n",
    "    classLoss = ClassLoss(y_true, y_pred)\n",
    "\n",
    "    return 25 * coordLoss + 15 * confidenceLoss + 5 * classLoss\n",
    "\n",
    "def CoordLoss(y_true, y_pred):\n",
    "    #find if it exist an object in the grid\n",
    "    existsObject = tf.expand_dims(y_true[..., 4], -1)\n",
    "\n",
    "    xy_pred = existsObject * y_pred[..., 0:2]\n",
    "    xy_true = existsObject * y_true[..., 0:2]\n",
    "\n",
    "    wh_pred = existsObject * tf.math.sign(y_pred[..., 2:4]) * tf.sqrt(tf.math.abs(y_pred[..., 2:4])) #if it's linear (-inf, inf)\n",
    "    wh_true = existsObject * tf.sqrt(y_true[..., 2:4])\n",
    "\n",
    "    coordLoss = tf.reduce_sum(tf.math.square(wh_pred - wh_true))\n",
    "    coordLoss += tf.reduce_sum(tf.math.square(xy_pred - xy_true))\n",
    "\n",
    "    return coordLoss / tf.cast(tf.math.count_nonzero(existsObject), dtype=tf.float32) #mean, but it's fine if we don't\n",
    "\n",
    "def ConfidenceLoss(y_true, y_pred):\n",
    "    existsObject = tf.expand_dims(y_true[..., 4], -1)\n",
    "\n",
    "    confidenceLoss = tf.reduce_sum(tf.math.square(existsObject * (y_true[..., 4:5] - y_pred[..., 4:5])))\n",
    "    confidenceLoss += 0.5*tf.reduce_sum(tf.math.square((1 - existsObject) * (y_true[..., 4:5] - y_pred[..., 4:5])))\n",
    "\n",
    "    return confidenceLoss / tf.cast(tf.math.count_nonzero(existsObject), dtype=tf.float32) #mean, but it's fine if we don't\n",
    "\n",
    "def ClassLoss(y_true, y_pred):\n",
    "    existsObject = tf.expand_dims(y_true[..., 4], -1)\n",
    "\n",
    "    classLoss = tf.reduce_sum(tf.math.square(existsObject * (y_true[..., 5:] - y_pred[..., 5:])))\n",
    "    return classLoss / tf.cast(tf.math.count_nonzero(existsObject), dtype=tf.float32) #mean, but it's fine if we don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = yoloLoss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=[CoordLoss, ConfidenceLoss, ClassLoss]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(  x \u001b[39m=\u001b[39;49m trainingDataGenerator,\n\u001b[0;32m      2\u001b[0m             validation_data \u001b[39m=\u001b[39;49m (validationDataGenerator),\n\u001b[0;32m      3\u001b[0m             epochs \u001b[39m=\u001b[39;49m \u001b[39m300\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m             workers \u001b[39m=\u001b[39;49m \u001b[39m8\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m             validation_freq \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\INFOSTAT-19\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m, in \u001b[0;36mDataGenerator.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m (np\u001b[39m.\u001b[39mceil(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages) \u001b[39m/\u001b[39m \u001b[39mint\u001b[39m(BATCH_SIZE)))\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(  x = trainingDataGenerator,\n",
    "            validation_data = (validationDataGenerator),\n",
    "            epochs = 300,\n",
    "            workers = 8,\n",
    "            validation_freq = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    image = cv.imread('annotations/Cats_Test20' + str(i) + '.png')\n",
    "    image = cv.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = image / 255.\n",
    "    TestPrint(image, model.predict(np.expand_dims(image, 0))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('yolov1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4647de65156ceaa16e73f62ac2f7016bf871fdf50544b59ca411d1eb6a409d29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
