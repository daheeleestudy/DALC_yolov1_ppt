{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a216237",
   "metadata": {},
   "source": [
    "Dataset and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6ae92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe8156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, csv_file, img_dir, label_dir, S=7, B=2, C=20, transform=None, #split size, num_boxes=B,num_classes=C\n",
    "    ):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir #이미지 디렉토리\n",
    "        self.label_dir = label_dir #레이블 디렉토리\n",
    "        self.transform = transform\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1]) #directory we saw in label ,first column file detect\n",
    "        boxes = []\n",
    "        with open(label_path) as f:\n",
    "            for label in f.readlines():\n",
    "                class_label, x, y, width, height = [\n",
    "                    float(x) if float(x) != int(float(x)) else int(x)\n",
    "                    for x in label.replace(\"\\n\", \"\").split() #class: int/ x,y,width,height는 float일 가능성 있음\n",
    "                ]\n",
    "\n",
    "                boxes.append([class_label, x, y, width, height])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0]) #index,0 -> 이미지 파일 이름, 디렉토리  \n",
    "        image = Image.open(img_path) #using PIL\n",
    "        boxes = torch.tensor(boxes)\n",
    "\n",
    "        if self.transform:\n",
    "            # image = self.transform(image)\n",
    "            image, boxes = self.transform(image, boxes)\n",
    "\n",
    "        # Convert To Cells\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B))  #one bbx per cell\n",
    "        for box in boxes:\n",
    "            class_label, x, y, width, height = box.tolist()\n",
    "            class_label = int(class_label) #convert everything into label matrix\n",
    "\n",
    "            # i,j represents the cell row and cell column\n",
    "            i, j = int(self.S * y), int(self.S * x) #y row that belongs to, x는 column??\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "\n",
    "            \"\"\"\n",
    "            Calculating the width and height of cell of bounding box,\n",
    "            relative to the cell is done by the following, with\n",
    "            width as the example:\n",
    "            \n",
    "            width_pixels = (width*self.image_width)\n",
    "            cell_pixels = (self.image_width)\n",
    "            \n",
    "            Then to find the width relative to the cell is simply:\n",
    "            width_pixels/cell_pixels, simplification leads to the\n",
    "            formulas below.\n",
    "            \"\"\"\n",
    "            width_cell, height_cell = (\n",
    "                width * self.S,\n",
    "                height * self.S, #width와 height는 전체 이미지와 관련있고, 하나에 셀에 원하는 경우,\n",
    "                                 # scale appropriately 쪼갠 셀에 적절히 스케일링\n",
    "            )\n",
    "\n",
    "            # If no object already found for specific cell i,j\n",
    "            # Note: This means we restrict to ONE object\n",
    "            # per cell!\n",
    "            if label_matrix[i, j, 20] == 0:\n",
    "                # Set that there exists an object\n",
    "                label_matrix[i, j, 20] = 1\n",
    "\n",
    "                # Box coordinates\n",
    "                box_coordinates = torch.tensor(\n",
    "                    [x_cell, y_cell, width_cell, height_cell]\n",
    "                )\n",
    "\n",
    "                label_matrix[i, j, 21:25] = box_coordinates\n",
    "\n",
    "                # Set one hot encoding for class_label\n",
    "                label_matrix[i, j, class_label] = 1\n",
    "\n",
    "        return image, label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abcc8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, csv_file, img_dir, label_dir, S=7, B=2, C=20, transform=None,\n",
    "    ):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1])\n",
    "        boxes = []\n",
    "        with open(label_path) as f:\n",
    "            for label in f.readlines():\n",
    "                class_label, x, y, width, height = [\n",
    "                    float(x) if float(x) != int(float(x)) else int(x)\n",
    "                    for x in label.replace(\"\\n\", \"\").split()\n",
    "                ]\n",
    "\n",
    "                boxes.append([class_label, x, y, width, height])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        boxes = torch.tensor(boxes)\n",
    "\n",
    "        if self.transform:\n",
    "            # image = self.transform(image)\n",
    "            image, boxes = self.transform(image, boxes)\n",
    "\n",
    "        # Convert To Cells\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B))\n",
    "        for box in boxes:\n",
    "            class_label, x, y, width, height = box.tolist()\n",
    "            class_label = int(class_label)\n",
    "\n",
    "            # i,j represents the cell row and cell column\n",
    "            i, j = int(self.S * y), int(self.S * x)\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "\n",
    "            \"\"\"\n",
    "            Calculating the width and height of cell of bounding box,\n",
    "            relative to the cell is done by the following, with\n",
    "            width as the example:\n",
    "            \n",
    "            width_pixels = (width*self.image_width)\n",
    "            cell_pixels = (self.image_width)\n",
    "            \n",
    "            Then to find the width relative to the cell is simply:\n",
    "            width_pixels/cell_pixels, simplification leads to the\n",
    "            formulas below.\n",
    "            \"\"\"\n",
    "            width_cell, height_cell = (\n",
    "                width * self.S,\n",
    "                height * self.S,\n",
    "            )\n",
    "\n",
    "            # If no object already found for specific cell i,j\n",
    "            # Note: This means we restrict to ONE object\n",
    "            # per cell!\n",
    "            if label_matrix[i, j, 20] == 0:\n",
    "                # Set that there exists an object\n",
    "                label_matrix[i, j, 20] = 1\n",
    "\n",
    "                # Box coordinates\n",
    "                box_coordinates = torch.tensor(\n",
    "                    [x_cell, y_cell, width_cell, height_cell]\n",
    "                )\n",
    "\n",
    "                label_matrix[i, j, 21:25] = box_coordinates\n",
    "\n",
    "                # Set one hot encoding for class_label\n",
    "                label_matrix[i, j, class_label] = 1\n",
    "\n",
    "        return image, label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c9a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class VOCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, csv_file, img_dir, label_dir, S=7, B=2, C=20, transform=None,\n",
    "    ):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1])\n",
    "        boxes = []\n",
    "        with open(label_path) as f:\n",
    "            for label in f.readlines():\n",
    "                class_label, x, y, width, height = [\n",
    "                    float(x) if float(x) != int(float(x)) else int(x)\n",
    "                    for x in label.replace(\"\\n\", \"\").split()\n",
    "                ]\n",
    "\n",
    "                boxes.append([class_label, x, y, width, height])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        boxes = torch.tensor(boxes)\n",
    "\n",
    "        if self.transform:\n",
    "            # image = self.transform(image)\n",
    "            image, boxes = self.transform(image, boxes)\n",
    "\n",
    "        # Convert To Cells\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B))\n",
    "        for box in boxes:\n",
    "            class_label, x, y, width, height = box.tolist()\n",
    "            class_label = int(class_label)\n",
    "\n",
    "            # i,j represents the cell row and cell column\n",
    "            i, j = int(self.S * y), int(self.S * x)\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "\n",
    "            \"\"\"\n",
    "            Calculating the width and height of cell of bounding box,\n",
    "            relative to the cell is done by the following, with\n",
    "            width as the example:\n",
    "            \n",
    "            width_pixels = (width*self.image_width)\n",
    "            cell_pixels = (self.image_width)\n",
    "            \n",
    "            Then to find the width relative to the cell is simply:\n",
    "            width_pixels/cell_pixels, simplification leads to the\n",
    "            formulas below.\n",
    "            \"\"\"\n",
    "            width_cell, height_cell = (\n",
    "                width * self.S,\n",
    "                height * self.S,\n",
    "            )\n",
    "\n",
    "            # If no object already found for specific cell i,j\n",
    "            # Note: This means we restrict to ONE object\n",
    "            # per cell!\n",
    "            if label_matrix[i, j, 20] == 0:\n",
    "                # Set that there exists an object\n",
    "                label_matrix[i, j, 20] = 1\n",
    "\n",
    "                # Box coordinates\n",
    "                box_coordinates = torch.tensor(\n",
    "                    [x_cell, y_cell, width_cell, height_cell]\n",
    "                )\n",
    "\n",
    "                label_matrix[i, j, 21:25] = box_coordinates\n",
    "\n",
    "                # Set one hot encoding for class_label\n",
    "                label_matrix[i, j, class_label] = 1\n",
    "\n",
    "        return image, label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b95a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
